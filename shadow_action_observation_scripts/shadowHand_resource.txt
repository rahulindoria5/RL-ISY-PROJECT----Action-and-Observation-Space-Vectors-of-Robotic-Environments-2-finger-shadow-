
# Note: all the observation vector values of shadow hand are placed in foo_0.csv file which is used to read and plot full graph for all time steps 

the camera angles used and which is changed on hard-code in the file

file to change --> ../baselines/env/lib/python3.6/site-packages/gym/envs/robotics/hand_env.py


providing the parameter values to change camera for different directions:

1. for above-view :
   distance = 0.55
   azimuth = -90.
   elevation = -90.
   
  --> for above crop value = (370,40,920,590)

2. for right-view :
   distance = 0.55
   azimuth = 180.
   elevation = -15.

  --> for right crop value = (230,180,780,730) 

3. for front-view :
   distance = 0.55
   azimuth = 90.
   elevation = -15.

  --> for front crop value = (370,270,920,820)

# Note: this crop value will change if you have different screen resolution (in my case 1440x900)


ffmpeg commands used :

1. For each png to video :
Terminal command → 
ffmpeg -framerate 5 -pattern_type glob -i '*.png' -b:v 10000k sample_output.mp4

2. For 3 videos on top and 1 video on bottom gride:
Terminal command →
ffmpeg -i sample-1.mp4 -i sample-2.mp4 -i sample-3.mp4 -i sample-4.mp4 -filter_complex “[0:v][1:v]hstack[top];[top][2:v]hstack[topall];[topall][3:v]vstack[v]” -map “[v]” -b:v 10000k sample_comb_output.mp4

